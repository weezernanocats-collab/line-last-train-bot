"""
çµ‚é›»æ¤œç´¢ LINE Bot

LINEã§é§…åã‚’é€ã‚‹ã¨ã€ãã®é§…ã‹ã‚‰è¥¿åƒè‘‰é§…ã¸ã®çµ‚é›»ã‚’èª¿ã¹ã¦è¿”ä¿¡ã™ã‚‹
"""

import os
import re
import json
import requests
from urllib.parse import quote
from datetime import datetime, timezone, timedelta
from flask import Flask, request, abort
from linebot.v3 import WebhookHandler
from linebot.v3.messaging import (
    Configuration,
    ApiClient,
    MessagingApi,
    ReplyMessageRequest,
    TextMessage,
)
from linebot.v3.webhooks import MessageEvent, TextMessageContent
from linebot.v3.exceptions import InvalidSignatureError
from bs4 import BeautifulSoup

app = Flask(__name__)

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’å–å¾—
LINE_CHANNEL_ACCESS_TOKEN = os.environ.get("LINE_CHANNEL_ACCESS_TOKEN", "")
LINE_CHANNEL_SECRET = os.environ.get("LINE_CHANNEL_SECRET", "")

# LINE Bot SDK v3 ã®è¨­å®š
configuration = Configuration(access_token=LINE_CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(LINE_CHANNEL_SECRET)

# ç›®çš„åœ°
DESTINATION_STATION = "è¥¿åƒè‘‰"

# Yahoo!è·¯ç·šæƒ…å ±ï¼ˆé–¢æ±ã‚¨ãƒªã‚¢ï¼‰ã®é…å»¶æƒ…å ±URL
YAHOO_TRANSIT_URL = "https://transit.yahoo.co.jp/diainfo/area/3"

# è¥¿åƒè‘‰é§…ã«é–¢é€£ã™ã‚‹è·¯ç·šï¼ˆé…å»¶ãƒã‚§ãƒƒã‚¯å¯¾è±¡ï¼‰
RELATED_LINES = [
    "ç·æ­¦ç·š",
    "ç·æ­¦æœ¬ç·š",
    "ä¸­å¤®ãƒ»ç·æ­¦ç·š",
    "äº¬è‘‰ç·š",
    "æ­¦è”µé‡ç·š",
    "äº¬æˆç·š",
    "äº¬æˆåƒè‘‰ç·š",
]


@app.route("/")
def index():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ç”¨"""
    return "LINE Last Train Bot is running!"


@app.route("/callback", methods=["POST"])
def callback():
    """LINE Webhookã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    signature = request.headers.get("X-Line-Signature", "")
    body = request.get_data(as_text=True)

    app.logger.info(f"Request body: {body}")

    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        app.logger.error("Invalid signature")
        abort(400)

    return "OK"


@handler.add(MessageEvent, message=TextMessageContent)
def handle_message(event):
    """ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ä¿¡ã—ãŸã¨ãã®å‡¦ç†"""
    user_message = event.message.text.strip()
    app.logger.info(f"Received message: {user_message}")

    # é§…åã‚’æŠ½å‡ºï¼ˆã‚·ãƒ³ãƒ—ãƒ«ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å…¨ä½“ã‚’é§…åã¨ã—ã¦æ‰±ã†ï¼‰
    station_name = extract_station_name(user_message)

    if not station_name:
        reply_text = "é§…åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚\nä¾‹: æ±äº¬ã€ç§‹è‘‰åŸã€åƒè‘‰"
    else:
        # çµ‚é›»ã‚’æ¤œç´¢
        reply_text = search_last_train(station_name, DESTINATION_STATION)

    # è¿”ä¿¡
    with ApiClient(configuration) as api_client:
        messaging_api = MessagingApi(api_client)
        messaging_api.reply_message(
            ReplyMessageRequest(
                reply_token=event.reply_token,
                messages=[TextMessage(text=reply_text)]
            )
        )


def extract_station_name(message):
    """
    ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰é§…åã‚’æŠ½å‡ºã™ã‚‹

    Args:
        message: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

    Returns:
        str: æŠ½å‡ºã—ãŸé§…åï¼ˆè¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã°Noneï¼‰
    """
    # ã€Œã€œé§…ã€ã¨ã„ã†å½¢å¼ãŒã‚ã‚Œã°æŠ½å‡º
    match = re.search(r"(.+?)é§…", message)
    if match:
        return match.group(1)

    # ã€Œã€œã‹ã‚‰ã€ã€Œã€œã§ã€ãªã©ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
    patterns = [
        r"(.+?)ã‹ã‚‰(?:å¸°|çµ‚é›»|é›»è»Š)",
        r"(.+?)ã§(?:é£²|éŠ|ä»•äº‹)",
        r"^([ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¥a-zA-Z]+)$",  # é§…åã®ã¿
    ]

    for pattern in patterns:
        match = re.search(pattern, message)
        if match:
            station = match.group(1).strip()
            # çŸ­ã™ãã‚‹å ´åˆã¯é™¤å¤–
            if len(station) >= 1:
                return station

    # ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ãƒãƒƒãƒã—ãªã‘ã‚Œã°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å…¨ä½“ã‚’é§…åã¨ã—ã¦æ‰±ã†
    # ãŸã ã—é•·ã™ãã‚‹å ´åˆã¯é™¤å¤–
    if len(message) <= 10:
        return message

    return None


def search_last_train(from_station, to_station):
    """
    Yahoo!è·¯ç·šæƒ…å ±ã§çµ‚é›»ã‚’æ¤œç´¢ã™ã‚‹

    Args:
        from_station: å‡ºç™ºé§…
        to_station: åˆ°ç€é§…

    Returns:
        str: æ¤œç´¢çµæœã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """
    try:
        # æ—¥æœ¬æ™‚é–“ã§ä»Šæ—¥ã®æ—¥ä»˜ã‚’å–å¾—
        jst = timezone(timedelta(hours=9))
        now = datetime.now(jst)

        # é…å»¶æƒ…å ±ã‚’å–å¾—
        delays = fetch_delay_info()

        # Yahoo!è·¯ç·šæƒ…å ±ã®URL
        # type=1: å‡ºç™ºæ™‚åˆ»æŒ‡å®šã€23:00ã§æ¤œç´¢ã—ã¦çµ‚é›»ã«è¿‘ã„é›»è»Šã‚’å–å¾—
        url = (
            f"https://transit.yahoo.co.jp/search/result"
            f"?from={quote(from_station)}"
            f"&to={quote(to_station)}"
            f"&y={now.year}&m={now.month:02d}&d={now.day:02d}"
            f"&hh=23&mm=00"
            f"&type=1"  # å‡ºç™ºæ™‚åˆ»æŒ‡å®š
            f"&ticket=ic"  # ICå„ªå…ˆ
            f"&s=1"  # æ™‚åˆ»é †
        )

        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }

        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        response.encoding = "utf-8"

        soup = BeautifulSoup(response.text, "html.parser")

        # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯ï¼ˆé§…ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆï¼‰
        error_elem = soup.select_one("div.elmErrorText, p.errTxt")
        if error_elem:
            return f"ã€Œ{from_station}ã€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\næ­£å¼ãªé§…åã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"

        # å€™è£œé§…ãŒè¤‡æ•°ã‚ã‚‹å ´åˆ
        candidate_list = soup.select("div.candiList a, ul.candidate a")
        if candidate_list:
            candidates = [a.get_text(strip=True) for a in candidate_list[:5]]
            return f"ã€Œ{from_station}ã€ã«è©²å½“ã™ã‚‹é§…ãŒè¤‡æ•°ã‚ã‚Šã¾ã™:\n" + "\n".join(f"ãƒ»{c}" for c in candidates)

        # JSONãƒ‡ãƒ¼ã‚¿ã‹ã‚‰çµŒè·¯æƒ…å ±ã‚’å–å¾—
        result = parse_route_from_json(soup, from_station, to_station)

        if not result:
            # JSONãŒå–å¾—ã§ããªã„å ´åˆã¯HTMLã‹ã‚‰ãƒ‘ãƒ¼ã‚¹
            result = parse_route_result(soup, from_station, to_station)

        if not result:
            return f"çµ‚é›»æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\nYahoo!è·¯ç·šæƒ…å ±ã§ç›´æ¥æ¤œç´¢ã—ã¦ãã ã•ã„ã€‚"

        # é…å»¶æƒ…å ±ãŒã‚ã‚Œã°è¿½åŠ 
        if delays:
            delay_msg = format_delay_info(delays)
            result = result + "\n" + delay_msg

            # é…å»¶æ™‚ã¯ä»£æ›¿ãƒ«ãƒ¼ãƒˆã‚’æ¤œç´¢
            alt_result = search_alternative_route(from_station, to_station, now)
            if alt_result:
                result = result + "\n" + alt_result

        return result

    except requests.Timeout:
        return "æ¤œç´¢ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚\nã—ã°ã‚‰ãã—ã¦ã‹ã‚‰ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
    except requests.RequestException as e:
        app.logger.error(f"Request error: {e}")
        return "æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\nã—ã°ã‚‰ãã—ã¦ã‹ã‚‰ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"


def format_delay_info(delays):
    """
    é…å»¶æƒ…å ±ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹

    Args:
        delays: é…å»¶æƒ…å ±ã®ãƒªã‚¹ãƒˆ

    Returns:
        str: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸé…å»¶æƒ…å ±
    """
    lines = [
        "",
        "âš ï¸ é‹è¡Œæƒ…å ± âš ï¸",
    ]

    for delay in delays[:3]:  # æœ€å¤§3ä»¶
        lines.append(f"ğŸ”´ {delay['line']}")
        lines.append(f"   {delay['status'][:50]}")

    return "\n".join(lines)


def search_alternative_route(from_station, to_station, now):
    """
    ä»£æ›¿ãƒ«ãƒ¼ãƒˆã‚’æ¤œç´¢ã™ã‚‹ï¼ˆé…å»¶æ™‚ç”¨ï¼‰

    Args:
        from_station: å‡ºç™ºé§…
        to_station: åˆ°ç€é§…
        now: ç¾åœ¨æ™‚åˆ»

    Returns:
        str: ä»£æ›¿ãƒ«ãƒ¼ãƒˆæƒ…å ±ï¼ˆãªã‘ã‚Œã°Noneï¼‰
    """
    try:
        # çµŒç”±é§…ã‚’å¤‰ãˆã¦æ¤œç´¢ï¼ˆä¾‹ï¼šæ±äº¬çµŒç”±ã€èˆ¹æ©‹çµŒç”±ãªã©ï¼‰
        via_stations = ["èˆ¹æ©‹", "æ´¥ç”°æ²¼", "åƒè‘‰"]

        for via in via_stations:
            if via == from_station or via == to_station:
                continue

            url = (
                f"https://transit.yahoo.co.jp/search/result"
                f"?from={quote(from_station)}"
                f"&to={quote(to_station)}"
                f"&via={quote(via)}"
                f"&y={now.year}&m={now.month:02d}&d={now.day:02d}"
                f"&hh=23&mm=30"
                f"&type=1"
                f"&ticket=ic"
            )

            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
            }

            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, "html.parser")

                # æ™‚åˆ»ã‚’å–å¾—
                time_match = re.search(r"(\d{1,2}:\d{2})ç™º.*?(\d{1,2}:\d{2})ç€", soup.get_text())
                if time_match:
                    return f"\nğŸ’¡ ä»£æ›¿ãƒ«ãƒ¼ãƒˆï¼ˆ{via}çµŒç”±ï¼‰\n   ç™ºè»Š {time_match.group(1)} â†’ åˆ°ç€ {time_match.group(2)}"

    except Exception as e:
        app.logger.error(f"Alternative route search error: {e}")

    return None


def fetch_delay_info():
    """
    Yahoo!è·¯ç·šæƒ…å ±ã‹ã‚‰é–¢é€£è·¯ç·šã®é…å»¶æƒ…å ±ã‚’å–å¾—ã™ã‚‹

    Returns:
        list: é…å»¶æƒ…å ±ã®ãƒªã‚¹ãƒˆ [{"line": è·¯ç·šå, "status": çŠ¶æ³}]
    """
    delays = []

    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        response = requests.get(YAHOO_TRANSIT_URL, headers=headers, timeout=10)
        response.raise_for_status()
        response.encoding = response.apparent_encoding

        soup = BeautifulSoup(response.text, "html.parser")

        # é‹è¡Œæƒ…å ±ã®ãƒªã‚¹ãƒˆã‚’å–å¾—
        trouble_items = soup.select("div.trouble a, li.elmTblLstLine a")

        for item in trouble_items:
            line_name = item.get_text(strip=True)

            # é–¢é€£è·¯ç·šã‹ãƒã‚§ãƒƒã‚¯
            for target in RELATED_LINES:
                if target in line_name:
                    # è©³ç´°ãƒšãƒ¼ã‚¸ã®URLã‚’å–å¾—
                    detail_url = item.get("href")
                    if detail_url and not detail_url.startswith("http"):
                        detail_url = "https://transit.yahoo.co.jp" + detail_url

                    status = fetch_delay_detail(detail_url) if detail_url else "é‹è¡Œæƒ…å ±ã‚ã‚Š"

                    delays.append({
                        "line": line_name,
                        "status": status
                    })
                    break

    except requests.RequestException as e:
        app.logger.error(f"é…å»¶æƒ…å ±ã®å–å¾—ã«å¤±æ•—: {e}")

    return delays


def fetch_delay_detail(url):
    """
    è©³ç´°ãƒšãƒ¼ã‚¸ã‹ã‚‰é…å»¶çŠ¶æ³ã‚’å–å¾—ã™ã‚‹

    Args:
        url: è©³ç´°ãƒšãƒ¼ã‚¸ã®URL

    Returns:
        str: é…å»¶çŠ¶æ³ã®è©³ç´°
    """
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        response.encoding = response.apparent_encoding

        soup = BeautifulSoup(response.text, "html.parser")

        # çŠ¶æ³ã®è©³ç´°ã‚’å–å¾—
        status_elem = soup.select_one("div.trouble p, p.trouble, div.statusTxt")
        if status_elem:
            return status_elem.get_text(strip=True)[:100]  # 100æ–‡å­—ã¾ã§

    except requests.RequestException:
        pass

    return "è©³ç´°æƒ…å ±å–å¾—å¤±æ•—"


def parse_route_from_json(soup, from_station, to_station):
    """
    ãƒšãƒ¼ã‚¸å†…ã®JSONãƒ‡ãƒ¼ã‚¿ã‹ã‚‰çµŒè·¯æƒ…å ±ã‚’å–å¾—ã™ã‚‹

    Args:
        soup: BeautifulSoupã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        from_station: å‡ºç™ºé§…
        to_station: åˆ°ç€é§…

    Returns:
        str: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸçµæœãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """
    try:
        # scriptã‚¿ã‚°ã‹ã‚‰JSONãƒ‡ãƒ¼ã‚¿ã‚’æ¢ã™
        route_data = None
        html_text = str(soup)

        # naviSearchParam ã‚’æ¢ã™ï¼ˆè¤‡æ•°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦ã™ï¼‰
        patterns = [
            r'naviSearchParam\s*=\s*(\{.+?\})\s*;',
            r'"featureInfoList"\s*:\s*(\[.+?\])\s*,\s*"edgeInfoList"',
        ]

        for pattern in patterns:
            match = re.search(pattern, html_text, re.DOTALL)
            if match:
                try:
                    if pattern.startswith('"feature'):
                        # éƒ¨åˆ†çš„ãªJSONã®å ´åˆ
                        feature_match = re.search(r'"featureInfoList"\s*:\s*(\[.+?\])', html_text, re.DOTALL)
                        edge_match = re.search(r'"edgeInfoList"\s*:\s*(\[.+?\]\s*\])', html_text, re.DOTALL)
                        if feature_match and edge_match:
                            route_data = {
                                "featureInfoList": json.loads(feature_match.group(1)),
                                "edgeInfoList": json.loads(edge_match.group(1))
                            }
                    else:
                        route_data = json.loads(match.group(1))
                    break
                except json.JSONDecodeError:
                    continue

        if not route_data:
            return None

        # æœ€å¾Œã®ãƒ«ãƒ¼ãƒˆï¼ˆæœ€ã‚‚é…ã„å‡ºç™ºï¼çµ‚é›»ã«è¿‘ã„ï¼‰ã‚’å–å¾—
        feature_list = route_data.get("featureInfoList", [])
        edge_list = route_data.get("edgeInfoList", [])

        if not feature_list or not edge_list:
            return None

        # æœ€å¾Œã®ãƒ«ãƒ¼ãƒˆã‚’å–å¾—ï¼ˆçµ‚é›»ã«è¿‘ã„ï¼‰
        last_idx = len(feature_list) - 1
        feature = feature_list[last_idx]
        edges = edge_list[last_idx] if last_idx < len(edge_list) else edge_list[0]

        # ç™ºè»Šãƒ»åˆ°ç€æ™‚åˆ»ã‚’å–å¾—
        dep_time = str(feature.get("departureTime", ""))
        arr_time = str(feature.get("arrivalTime", ""))

        # æ™‚åˆ»ã‹ã‚‰HH:MMéƒ¨åˆ†ã®ã¿æŠ½å‡º
        time_match = re.search(r"(\d{1,2}:\d{2})", dep_time)
        dep_time = time_match.group(1) if time_match else dep_time

        time_match = re.search(r"(\d{1,2}:\d{2})", arr_time)
        arr_time = time_match.group(1) if time_match else arr_time

        # ä¹—æ›å›æ•°
        transfer_count = feature.get("transferCount", 0)
        if isinstance(transfer_count, str):
            transfer_count = int(transfer_count) if transfer_count.isdigit() else 0

        # çµæœã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        lines = [
            f"ğŸšƒ {from_station} â†’ {to_station}",
            "",
            f"ç™ºè»Š {dep_time} â†’ åˆ°ç€ {arr_time}",
        ]

        if transfer_count > 0:
            lines.append(f"ä¹—æ› {transfer_count}å›")

        # è©³ç´°ãªä¹—ã‚Šæ›ãˆæƒ…å ±ã‚’å–å¾—
        lines.append("")
        lines.append("â”â”â” ä¹—æ›æ¡ˆå†… â”â”â”")

        for edge in edges:
            if not isinstance(edge, dict):
                continue

            rail_name = edge.get("railName", "")
            if not rail_name:
                continue

            # é§…å
            station_name = edge.get("stationName", "")

            # æ™‚åˆ»æƒ…å ±
            time_info = edge.get("timeInfo", [])
            edge_dep_time = ""
            edge_arr_time = ""

            for t in time_info:
                if isinstance(t, dict):
                    if t.get("type") == "departure" or "ç™º" in str(t):
                        edge_dep_time = t.get("time", "")
                    elif t.get("type") == "arrival" or "ç€" in str(t):
                        edge_arr_time = t.get("time", "")

            # ç•ªç·šæƒ…å ±
            dep_platform = ""
            arr_platform = ""
            riding_info = edge.get("ridingPositionInfo", {})
            if isinstance(riding_info, dict):
                dep_info = riding_info.get("departure", [])
                if isinstance(dep_info, list):
                    dep_platform = "".join(str(x) for x in dep_info)
                elif dep_info:
                    dep_platform = str(dep_info)

            # è·¯ç·šã¨é§…æƒ…å ±ã‚’è¡¨ç¤º
            lines.append("")
            lines.append(f"â–¶ {rail_name}")

            if station_name:
                time_str = ""
                if edge_dep_time:
                    time_str = f" {edge_dep_time}ç™º"
                elif edge_arr_time:
                    time_str = f" {edge_arr_time}ç€"

                platform_str = f" [{dep_platform}]" if dep_platform else ""
                lines.append(f"  {station_name}{time_str}{platform_str}")

        lines.extend([
            "",
            "â€» é‹è¡ŒçŠ¶æ³ã«ã‚ˆã‚Šå¤‰æ›´ã®å ´åˆã‚ã‚Š",
        ])

        return "\n".join(lines)

    except Exception as e:
        app.logger.error(f"JSON parse error: {e}")
        return None


def parse_route_result(soup, from_station, to_station):
    """
    æ¤œç´¢çµæœãƒšãƒ¼ã‚¸ã®HTMLã‹ã‚‰çµŒè·¯æƒ…å ±ã‚’ãƒ‘ãƒ¼ã‚¹ã™ã‚‹ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰

    Args:
        soup: BeautifulSoupã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        from_station: å‡ºç™ºé§…
        to_station: åˆ°ç€é§…

    Returns:
        str: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸçµæœãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """
    try:
        all_text = soup.get_text()

        # ç™ºç€æ™‚åˆ»ã‚’æ¢ã™ï¼ˆæœ€å¾Œã®ãƒ«ãƒ¼ãƒˆã‚’å–å¾—ã™ã‚‹ãŸã‚å…¨ã¦æ¢ã™ï¼‰
        dep_times = re.findall(r"(\d{1,2}:\d{2})ç™º", all_text)
        arr_times = re.findall(r"(\d{1,2}:\d{2})ç€", all_text)

        # æœ€å¾Œã®ãƒ«ãƒ¼ãƒˆï¼ˆçµ‚é›»ã«è¿‘ã„ï¼‰ã‚’å–å¾—
        dep_time = dep_times[-1] if dep_times else None
        arr_time = arr_times[-1] if arr_times else None

        if not dep_time:
            times = re.findall(r"(\d{1,2}:\d{2})", all_text)
            if len(times) >= 2:
                # å¾Œã‚ã®æ–¹ã®æ™‚åˆ»ã‚’ä½¿ã†
                dep_time = times[-2] if len(times) > 2 else times[0]
                arr_time = times[-1]

        # è·¯ç·šåã‚’æ¢ã™
        line_names = []
        line_matches = re.findall(r"(JR[^\s]+è¡Œ|[^\s]+ç·š[^\s]*è¡Œ)", all_text)
        if line_matches:
            line_names = list(set(line_matches))[:3]

        # ç•ªç·šæƒ…å ±ã‚’æ¢ã™
        platform_matches = re.findall(r"(\d+ç•ªç·š)", all_text)

        # çµæœã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        if dep_time:
            lines = [
                f"ğŸšƒ {from_station} â†’ {to_station}",
                "",
                f"ç™ºè»Š {dep_time} â†’ åˆ°ç€ {arr_time}" if arr_time else f"ç™ºè»Š {dep_time}",
            ]

            if line_names:
                lines.append("")
                lines.append("â”â”â” ä¹—æ›æ¡ˆå†… â”â”â”")
                for i, line_name in enumerate(line_names):
                    platform = platform_matches[i] if i < len(platform_matches) else ""
                    platform_str = f" [{platform}]" if platform else ""
                    lines.append(f"â–¶ {line_name}{platform_str}")

            lines.extend([
                "",
                "â€» è©³ç´°ã¯Yahoo!è·¯ç·šæƒ…å ±ã§ç¢ºèªã—ã¦ãã ã•ã„",
            ])

            return "\n".join(lines)

        return None

    except Exception as e:
        app.logger.error(f"Parse error: {e}")
        return None


if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port, debug=False)
